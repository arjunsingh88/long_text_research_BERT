{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach : New model with sentence wise sentiment computation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "import pandas as pd\n",
    "\n",
    "import time \n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "pd.options.display.float_format = '{:.10f}'.format\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load newly trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"nlptown/bert-base-multilingual-uncased-sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize our model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast = True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n",
    "# old_sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model ,tokenizer=tokenizer,  top_k=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Custom functions to increase text readability + sentence wise sentiment "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3.1: Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cleaning steps include:\n",
    "    # Removing non-alphanumeric characters and specific French characters.\n",
    "    # Removing URLs.\n",
    "    # Removing \"rt\" (retweet) tags.\n",
    "    # Removing excessive spaces and replacing consecutive spaces with a single space.\n",
    "    # Stripping leading and trailing whitespace.\n",
    "    # Replacing newline characters with spaces.\n",
    "    # Removing the possessive form \"'s\" by replacing it with \"s\".\n",
    "    # If any error occurs during the cleaning process, an error message is printed, and the original text is returned without any modifications.\n",
    "\n",
    "def clean_string(text:str) -> str:\n",
    "    try: \n",
    "        # utf8_apostrophe = b'\\xe2\\x80\\x99'.decode(\"utf8\")\n",
    "        DATE_REGEX = r\"\\d+\\/\\d+\\/\\d+\" # Regular expression pattern for matching date format\n",
    "        text = re.sub(r\"([^0-9A-Za-z àâäèéêëîïôœùûüÿçÀÂÄÈÉÊËÎÏÔŒÙÛÜŸÇ\\~\\°\\&\\“\\%\\'\\:\\;\\!\\-\\’\\\"\\.\\,\\?\\€\\$\\t\\n`(\\d+\\/\\d+\\/\\d+)``\\(.*\\)`])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\n",
    "        # Remove unwanted characters, URLs, and RT tags from the text\n",
    "        text = re.sub(' {2,}', ' ', text) # Remove inconsistent spaces (2 or more spaces become a single space)\n",
    "        text = re.sub(' \\. ', '.', text) # Remove inconsistent spaces around periods\n",
    "        # text = re.sub(utf8_apostrophe, \"'\", text)  # Substitute UTF-8 apostrophe with a regular apostrophe\n",
    "        text = text.strip()  # Strip leading and trailing whitespace\n",
    "        text = re.sub(r\"\\n\", \" \", text) # Replace newline characters with a space\n",
    "        text = re.sub(r\"\\'s\\b\", \"s\", text) # Replace \"'s\" with \"s\" (possessive form)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning text: {e}\")\n",
    "        return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3.2: function to compute sentiment for entire article (going through one sentence at a time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_sentiment(html_content:str, title_sentences:str, name:str, model, tokenizer ):\n",
    "    \"\"\"\n",
    "    Calculates the sentiment score and mentions of a given HTML content and title sentences.\n",
    "    Computation done sentence wise and not 512 token paragraph wise\n",
    "\n",
    "    Args:\n",
    "    - html_content (str): The HTML content to analyze.\n",
    "    - title_sentences (str): The title sentences used for sentiment comparison.\n",
    "    - name (str): The name to search for mentions.\n",
    "    - model: The sentiment analysis model.\n",
    "    - tokenizer: The tokenizer used for text encoding.\n",
    "\n",
    "    Returns:\n",
    "    - article_score (float): The calculated sentiment score for the article.\n",
    "    - mentions (int): The number of mentions of the given name in the content.\n",
    "\n",
    "    \"\"\"\n",
    "    # A quick cleaninig of html_content and title\n",
    "    html_content = clean_string(text = html_content)  #\n",
    "    title_sentences = clean_string(text = title_sentences) #\n",
    "    html_content = re.sub(re.escape(title_sentences), \"\", html_content) # this code eliminates the duplicated title text in html_content\n",
    "    \n",
    "    # Split the content into sentences\n",
    "    content_sentences = nltk.sent_tokenize(html_content)\n",
    "    \n",
    "    # Tokenize and encode content sentences using the provided tokenizer\n",
    "    content_inputs = tokenizer(content_sentences,  padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    #  torch.no_grad() = context manager that temporarily disables gradient calculation, which reduces memory usage and \n",
    "    #  speeds up computation when you only need to perform forward passes through the network (e.g., during inference).\n",
    "    # Perform sentiment analysis on the content sentences using the provided model\n",
    "    with torch.no_grad(): \n",
    "        content_outputs = model(**content_inputs)\n",
    "\n",
    "    # Softmax for probability scaling, i.e. sum of all probabilities = 1    \n",
    "    content_scores = torch.nn.functional.softmax(content_outputs.logits, dim=-1)\n",
    "    # Define the scale and shift it, in this case to --> -1, -0.5, 0, 0.5, 1\n",
    "    weights = torch.linspace(-1, 1, content_scores.shape[1])\n",
    "    normalised_content_scores = torch.matmul(content_scores, weights).tolist()\n",
    "    \n",
    "\n",
    "    # For title content\n",
    "    title_inputs = tokenizer(title_sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():       \n",
    "        title_outputs = model(**title_inputs)\n",
    "    title_scores = torch.nn.functional.softmax(title_outputs.logits, dim=-1)\n",
    "    normalised_title_scores = torch.matmul(title_scores, weights).tolist()\n",
    "\n",
    "    mentions = 0\n",
    "    score = 0.0\n",
    "    count = 0\n",
    "    # Iterate through content sentences and calculate sentiment scores\n",
    "    for sentence, sentiment in zip(content_sentences, normalised_content_scores):\n",
    "        multiplier = 1\n",
    "        if name.lower() in sentence.lower():\n",
    "            mentions += sentence.lower().count(name.lower())\n",
    "            multiplier = 5\n",
    "\n",
    "        count += multiplier\n",
    "        score += sentiment * multiplier\n",
    "\n",
    "    # Iterate through title sentences and calculate sentiment scores\n",
    "    for sentence, sentiment in zip(title_sentences, normalised_title_scores):\n",
    "        mentions += sentence.lower().count(name.lower())\n",
    "        multiplier = 5\n",
    "        count += multiplier\n",
    "        score += sentiment * multiplier\n",
    "\n",
    "    average_score = score / count\n",
    "    article_score = average_score * 50 + 50\n",
    "\n",
    "    return round(article_score, 5), mentions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: pytorch optimized compute sentiment functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _calculate_sentiment(html_content:str, title_sentences:str, name:str, model, tokenizer ):\n",
    "\n",
    "#     # For html_content\n",
    "#     html_content = clean_string(text = html_content)  #\n",
    "#     title_sentences = clean_string(text = title_sentences) #\n",
    "#     html_content = re.sub(re.escape(title_sentences), \"\", html_content) # this code eliminates the duplicated title text in html_content\n",
    "    \n",
    "#     content_inputs = tokenizer.encode_plus(html_content, add_special_tokens=False, return_tensors='pt').to(device)\n",
    "#     input_dict = _long_text(content_inputs, chunksize = 512)\n",
    "#     with torch.no_grad(): \n",
    "#         content_outputs = model(**input_dict)\n",
    "#     content_sentences = tokenizer.batch_decode(input_dict['input_ids'],skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "#     # # old approach\n",
    "#     # content_sentences = nltk.sent_tokenize(html_content)\n",
    "#     # content_inputs = tokenizer(content_sentences,  padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "#     # with torch.no_grad(): \n",
    "#     # #  torch.no_grad() = context manager that temporarily disables gradient calculation, which reduces memory usage and \n",
    "#     # #  speeds up computation when you only need to perform forward passes through the network (e.g., during inference).\n",
    "#     #     content_outputs = model(**content_inputs)\n",
    "\n",
    "#     content_scores = torch.nn.functional.softmax(content_outputs.logits, dim=-1)\n",
    "#     normalised_content_scores = torch.matmul(\n",
    "#         content_scores, torch.tensor([-1.0, -0.5, 0, 0.5, 1.0])\n",
    "#     ).tolist()\n",
    "    \n",
    "\n",
    "#     # For title content\n",
    "#     title_inputs = tokenizer(title_sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "#     with torch.no_grad():       \n",
    "#         title_outputs = model(**title_inputs)\n",
    "#     title_scores = torch.nn.functional.softmax(title_outputs.logits, dim=-1)\n",
    "#     normalised_title_scores = torch.matmul(\n",
    "#         title_scores, torch.tensor([-1.0, -0.5, 0, 0.5, 1.0])\n",
    "#     ).tolist()\n",
    "\n",
    "#     mentions = 0\n",
    "#     score = 0.0\n",
    "#     count = 0\n",
    "#     for sentence, sentiment in zip(\n",
    "#         content_sentences, normalised_content_scores\n",
    "#     ):\n",
    "#         multiplier = 1\n",
    "#         if name.lower() in sentence.lower():\n",
    "#             mentions += sentence.lower().count(name.lower())\n",
    "#             multiplier = 5\n",
    "\n",
    "#         count += multiplier\n",
    "#         score += sentiment * multiplier\n",
    "\n",
    "#     for sentence, sentiment in zip(title_sentences, normalised_title_scores):\n",
    "#         mentions += sentence.lower().count(name.lower())\n",
    "#         multiplier = 5\n",
    "#         count += multiplier\n",
    "#         score += sentiment * multiplier\n",
    "\n",
    "#     average_score = score / count\n",
    "#     article_score = average_score * 50 + 50\n",
    "\n",
    "#     return round(article_score, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_sentiment(html_content:str, title_sentences:str, name:str, model, tokenizer ):\n",
    "\n",
    "#         # New approach\n",
    "#         html_content = clean_string(text = html_content)  #\n",
    "#         title_sentences = clean_string(text = title_sentences) #\n",
    "        \n",
    "#         content_inputs = tokenizer.encode_plus(html_content, add_special_tokens=False, return_tensors='pt')\n",
    "#         input_dict = _long_text(content_inputs, chunksize = 512)\n",
    "#         content_outputs = model(**input_dict)\n",
    "#         content_sentences = [clean_string(tokenizer.decode(ids, skip_special_tokens=True)) for ids in input_dict['input_ids']]\n",
    "\n",
    "#         # old approach\n",
    "#         # title_sentences = re.sub(r\"[^A-Za-z0-9 .,]+\", \"\", title_sentences)\n",
    "#         # html_content = re.sub(r\"[^A-Za-z0-9 .,]+\", \"\",html_content )\n",
    "#         # content_sentences = nltk.sent_tokenize(html_content)\n",
    "#         # content_inputs = tokenizer(content_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "#         # content_outputs = model(**content_inputs)\n",
    "#         content_scores = torch.nn.functional.softmax(content_outputs.logits, dim=-1)\n",
    "#         weights = torch.linspace(-1, 1, content_scores.shape[1])\n",
    "\n",
    "#         normalised_content_scores = torch.matmul(content_scores, weights)\n",
    "        \n",
    "#         title_inputs = tokenizer(title_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "#         title_outputs = model(**title_inputs)\n",
    "#         title_scores = torch.nn.functional.softmax(title_outputs.logits, dim=-1)\n",
    "#         normalised_title_scores = torch.matmul(title_scores, weights)\n",
    "\n",
    "#         scores = torch.cat((normalised_content_scores, normalised_title_scores),0)\n",
    "#         print(f\"content scores: {content_scores}, normalized: {normalised_content_scores}\")\n",
    "#         print(f\"title scores: {title_scores}, normalized: {normalised_title_scores}\")\n",
    "#         print(scores)\n",
    "#         mentions = ' '.join([title_sentences, html_content]).lower().count(name.lower())\n",
    "#         article_score = (torch.mean(scores) + 1) * 50\n",
    "\n",
    "\n",
    "#         # print(torch.cat([content_scores, title_scores],0).mean(dim=0))\n",
    "#         # print(torch.matmul(torch.cat([content_scores, title_scores],0).mean(dim=0),torch.linspace(1,5, content_scores.shape[1])))\n",
    "\n",
    "#         return round(article_score.item(), 5)#, mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_sentiment(html_content:str, title_sentences:str, name:str, model, tokenizer ):\n",
    "\n",
    "#         # New approach\n",
    "#         html_content = clean_string(text = html_content)  #\n",
    "#         title_sentences = clean_string(text = title_sentences) #\n",
    "#         article_sentences = '. '.join([title_sentences,html_content])\n",
    "#         content_inputs = tokenizer.encode_plus(article_sentences, add_special_tokens=False, return_tensors='pt')\n",
    "#         input_dict = _long_text(content_inputs, chunksize = 512)\n",
    "#         content_outputs = model(**input_dict)\n",
    "#         # content_sentences = [clean_string(tokenizer.decode(ids, skip_special_tokens=True)) for ids in input_dict['input_ids']]\n",
    "\n",
    "\n",
    "#         content_scores = torch.nn.functional.softmax(content_outputs.logits, dim=-1)\n",
    "\n",
    "#         tensor_list = torch.split(content_scores, 1, dim=0)\n",
    "#         stacks = torch.stack(tensor_list)\n",
    "#         stacks = stacks.view(stacks.shape[0], stacks.shape[2])\n",
    "#         # finally, we can calculate the mean value for each sentiment class\n",
    "#         weights = torch.linspace(-1, 1, content_scores.shape[1]) # -1, -0.5, 0, 0.5, 1\n",
    "#         average_para_scores = stacks.mean(dim=0)\n",
    "\n",
    "#         scaled_scores = torch.matmul(average_para_scores, weights)\n",
    "#         print(average_para_scores)\n",
    "#         print(torch.argmax(average_para_scores).item()+1)\n",
    "#         article_score = (torch.mean(scaled_scores) + 1) * 50\n",
    "\n",
    "#         # print(torch.cat([content_scores, title_scores],0).mean(dim=0))\n",
    "#         # print(torch.matmul(torch.cat([content_scores, title_scores],0).mean(dim=0),torch.linspace(1,5, content_scores.shape[1])))\n",
    "\n",
    "#         return round(article_score.item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text = \"What is Volkswagen accused of?\\nIt's been dubbed the \\\"diesel dupe\\\". In September, the Environmental Protection Agency (EPA) found that many VW cars being sold in America had a \\\"defeat device\\\" - or software - in diesel engines that could detect when they were being tested, changing the performance accordingly to improve results. The German car giant has since admitted cheating emissions tests in the US.\\nVW has had a major push to sell diesel cars in the US, backed by a huge marketing campaign trumpeting its cars' low emissions. The EPA's findings cover 482,000 cars in the US only, including the VW-manufactured Audi A3, and the VW models Jetta, Beetle, Golf and Passat. But VW has admitted that about 11 million cars worldwide, including eight million in Europe, are fitted with the so-called \\\"defeat device\\\".\\nThe company has also been accused by the EPA of modifying software on the 3 litre diesel engines fitted to some Porsche and Audi as well as VW models. VW has denied the claims, which affect at least 10,000 vehicles.\\nIn November, VW said it had found \\\"irregularities\\\" in tests to measure carbon dioxide emissions levels that could affect about 800,000 cars in Europe - including petrol vehicles. However, in December it said that following investigations, it had established that this only affected about 36,000 of the cars it produces each year.\\nThis 'defeat device' sounds like a sophisticated piece of kit.\\nFull details of how it worked are sketchy, although the EPA has said that the engines had computer software that could sense test scenarios by monitoring speed, engine operation, air pressure and even the position of the steering wheel.\\nWhen the cars were operating under controlled laboratory conditions - which typically involve putting them on a stationary test rig - the device appears to have put the vehicle into a sort of safety mode in which the engine ran below normal power and performance. Once on the road, the engines switched out of this test mode.\\nThe result? The engines emitted nitrogen oxide pollutants up to 40 times above what is allowed in the US.\\nWhat has been VW's response?\\n\\\"We've totally screwed up,\\\" said VW America boss Michael Horn, while the group's chief executive at the time, Martin Winterkorn, said his company had \\\"broken the trust of our customers and the public\\\". Mr Winterkorn resigned as a direct result of the scandal and was replaced by Matthias Mueller, the former boss of Porsche.\\n\\\"My most urgent task is to win back trust for the Volkswagen Group - by leaving no stone unturned,\\\" Mr Mueller said on taking up his new post.\\nVW has also launched an internal inquiry.\\nBut that's unlikely to be the end of the financial impact. The EPA has the power to fine a company up to $37,500 for each vehicle that breaches standards - a maximum fine of about $18bn.\\nThe costs of possible legal action by car owners and shareholders \\\"cannot be estimated at the current time\\\", VW added.\\nHow widespread are VW's problems?\\nWhat started in the US has spread to a growing number of countries. The UK, Italy, France, South Korea, Canada and, of course, Germany, have opened investigations. Throughout the world, politicians, regulators and environmental groups are questioning the legitimacy of VW's emissions testing.\\nVW will recall 8.5 million cars in Europe, including 2.4 million in Germany and 1.2 million in the UK, and 500,000 in the US as a result of the emissions scandal.\\nNo wonder the carmaker's shares have fallen by about a third since the scandal broke.\\nWill more heads roll?\\nIt's still unclear who knew what and when, although VW must have had a chain of management command that approved fitting cheating devices to its engines, so further departures are likely.\\nChristian Klingler, a management board member and head of sales and marketing is leaving the company, although VW said this was part of long-term planned structural changes and was not related to recent events.\\nIn 2014, in the US, regulators raised concerns about VW emissions levels, but these were dismissed by the company as \\\"technical issues\\\" and \\\"unexpected\\\" real-world conditions. If executives and managers wilfully misled officials (or their own VW superiors) it's difficult to see them surviving.\\nAre other carmakers implicated?\\nThat's for the various regulatory and government inquiries to determine. California's Air Resources Board is now looking into other manufacturers' testing results. Ford, BMW and Renault-Nissan have said they did not use \\\"defeat devices\\\", while other firms have either not commented or simply stated that they comply with the law.\\nThe UK trade body for the car industry, the SMMT, said: \\\"The EU operates a fundamentally different system to the US - with all European tests performed in strict conditions as required by EU law and witnessed by a government-appointed independent approval agency.\\\"\\nBut it added: \\\"The industry acknowledges that the current test method is outdated and is seeking agreement from the European Commission for a new emissions test that embraces new testing technologies and is more representative of on-road conditions.\\\"\\nThat sounds like EU testing rules need tightening, too.\\nEnvironmental campaigners have long argued that emissions rules are being flouted. \\\"Diesel cars in Europe operate with worse technology on average than the US,\\\" said Jos Dings, from the pressure group Transport & Environment. \\\"Our latest report demonstrated that almost 90% of diesel vehicles didn't meet emission limits when they drive on the road. We are talking millions of vehicles.\\\"\\nCar analysts at the financial research firm Bernstein agree that European standards are not as strict as those in the US. However, the analysts said in a report that there was, therefore, \\\"less need to cheat\\\". So, if other European carmakers' results are suspect, Bernstein says the \\\"consequences are likely to be a change in the test cycle rather than legal action and fines\\\".\\nIt's all another blow for the diesel market.\\nCertainly is. Over the past decade and more, carmakers have poured a fortune into the production of diesel vehicles - with the support of many governments - believing that they are better for the environment. Latest scientific evidence suggests that's not the case, and there are even moves to limit diesel cars in some cities.\\nDiesel sales were already slowing, so the VW scandal came at a bad time. \\\"The revelations are likely to lead to a sharp fall in demand for diesel engine cars,\\\" said Richard Gane, automotive expert at consultants Vendigital.\\n\\\"In the US, the diesel car market currently represents around 1% of all new car sales and this is unlikely to increase in the short to medium term.\\n\\\"However, in Europe the impact could be much more significant, leading to a large tranche of the market switching to petrol engine cars virtually overnight.\\\"\"\n",
    "summary = \"In September, the Environmental Protection Agency (EPA) found that many VW cars being sold in America had a \\\"defeat device\\\" - or software - in diesel engines that could detect when they were being tested, changing the performance accordingly to improve results. VW has had a major push to sell diesel cars in the US, backed by a huge marketing campaign trumpeting its cars' low emissions. The company has also been accused by the EPA of modifying software on the 3 litre diesel engines fitted to some Porsche and Audi as well as VW models. In November, VW said it had found \\\"irregularities\\\" in tests to measure carbon dioxide emissions levels that could affect about 800,000 cars in Europe - including petrol vehicles. VW will recall 8.5 million cars in Europe, including 2.4 million in Germany and 1.2 million in the UK, and 500,000 in the US as a result of the emissions scandal.\"\n",
    "title = \"Volkswagen: The scandal explained - BBC News\"\n",
    "name = \"Volkswagen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_score, _ = _calculate_sentiment(html_content = html_text, title_sentences = title,name = name, model = model, tokenizer= tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.10496"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('bert_cloudrun')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1975ba15f5c6f49e9393a9ffcbc1714a9b9c74c65b1617749f5a6fb7923474c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
