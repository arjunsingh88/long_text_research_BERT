{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach : Chunking the entire article into multiple windows of fix size of 512 tokens and feeding them one after another"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "import pandas as pd\n",
    "\n",
    "import time \n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "pd.options.display.float_format = '{:.10f}'.format\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load newly trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"nlptown/bert-base-multilingual-uncased-sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize our model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast = True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n",
    "# old_sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model ,tokenizer=tokenizer,  top_k=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Custom functions to increase text readability + head and tail 512 text + compute sentiment "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3.1: Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cleaning steps include:\n",
    "    # Removing non-alphanumeric characters and specific French characters.\n",
    "    # Removing URLs.\n",
    "    # Removing \"rt\" (retweet) tags.\n",
    "    # Removing excessive spaces and replacing consecutive spaces with a single space.\n",
    "    # Stripping leading and trailing whitespace.\n",
    "    # Replacing newline characters with spaces.\n",
    "    # Removing the possessive form \"'s\" by replacing it with \"s\".\n",
    "    # If any error occurs during the cleaning process, an error message is printed, and the original text is returned without any modifications.\n",
    "\n",
    "def clean_string(text:str) -> str:\n",
    "    try: \n",
    "        # utf8_apostrophe = b'\\xe2\\x80\\x99'.decode(\"utf8\")\n",
    "        DATE_REGEX = r\"\\d+\\/\\d+\\/\\d+\" # Regular expression pattern for matching date format\n",
    "        text = re.sub(r\"([^0-9A-Za-z àâäèéêëîïôœùûüÿçÀÂÄÈÉÊËÎÏÔŒÙÛÜŸÇ\\~\\°\\&\\“\\%\\'\\:\\;\\!\\-\\’\\\"\\.\\,\\?\\€\\$\\t\\n`(\\d+\\/\\d+\\/\\d+)``\\(.*\\)`])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\n",
    "        # Remove unwanted characters, URLs, and RT tags from the text\n",
    "        text = re.sub(' {2,}', ' ', text) # Remove inconsistent spaces (2 or more spaces become a single space)\n",
    "        text = re.sub(' \\. ', '.', text) # Remove inconsistent spaces around periods\n",
    "        # text = re.sub(utf8_apostrophe, \"'\", text)  # Substitute UTF-8 apostrophe with a regular apostrophe\n",
    "        text = text.strip()  # Strip leading and trailing whitespace\n",
    "        text = re.sub(r\"\\n\", \" \", text) # Replace newline characters with a space\n",
    "        text = re.sub(r\"\\'s\\b\", \"s\", text) # Replace \"'s\" with \"s\" (possessive form)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning text: {e}\")\n",
    "        return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3.2: Create custom 512 token paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _long_text(tokens, chunksize):\n",
    "    \"\"\"\n",
    "    Splits a long text into chunks of a specified size and prepares the input tensors for the chunks.\n",
    "    \n",
    "    Args:\n",
    "        tokens (dict): Dictionary containing the tokenized text tensors, including 'input_ids' and 'attention_mask'.\n",
    "        chunksize (int): The desired size of each text chunk.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing the input tensors for the text chunks, including 'input_ids' and 'attention_mask'.\n",
    "    \"\"\"\n",
    "    # Avoided adding special tokens add_special_tokens=False because this will add [CLS] and [SEP] tokens to the start and end of the full tokenized tensor \n",
    "    # we will instead add them manually later.\n",
    "    # We will not specify max_length, truncation, or padding parameters (as we do not use any of them here).\n",
    "    # tokenizer = AutoTokenizer.from_pretrained(option)\n",
    "    # define target chunksize\n",
    "    \n",
    "\n",
    "    # split into chunks of chunksize tokens, we also convert to list (default is tuple which is immutable)\n",
    "    input_id_chunks = list(tokens['input_ids'][0].split(chunksize - 2))\n",
    "    mask_chunks = list(tokens['attention_mask'][0].split(chunksize - 2))\n",
    "\n",
    "    # loop through each chunk\n",
    "    for i in range(len(input_id_chunks)):\n",
    "        # add CLS and SEP tokens to input IDs\n",
    "        input_id_chunks[i] = torch.cat([\n",
    "            torch.tensor([101]), input_id_chunks[i], torch.tensor([102])\n",
    "        ])\n",
    "        # add attention tokens to attention mask\n",
    "        mask_chunks[i] = torch.cat([\n",
    "            torch.tensor([1]), mask_chunks[i], torch.tensor([1])\n",
    "        ])\n",
    "        # get required padding length\n",
    "        pad_len = chunksize - input_id_chunks[i].shape[0]\n",
    "        # check if tensor length satisfies required chunk size\n",
    "        if pad_len > 0:\n",
    "            # if padding length is more than 0, we must add padding\n",
    "            input_id_chunks[i] = torch.cat([\n",
    "                input_id_chunks[i], torch.Tensor([0] * pad_len)\n",
    "            ])\n",
    "            mask_chunks[i] = torch.cat([\n",
    "                mask_chunks[i], torch.Tensor([0] * pad_len)\n",
    "            ])\n",
    "\n",
    "    # Since we have different sections based on the token limit of 512 we will stack result using torch.stack\n",
    "    input_ids = torch.stack(input_id_chunks)\n",
    "    attention_mask = torch.stack(mask_chunks)\n",
    "\n",
    "    input_dict = {\n",
    "        'input_ids': input_ids.long(),\n",
    "        'attention_mask': attention_mask.int()\n",
    "    }\n",
    "    \n",
    "\n",
    "    return input_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3.3: function to compute sentiment for entire 5article split into paragraphs of 512 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_sentiment(html_content:str, title_sentences:str, name:str, model, tokenizer ):\n",
    "    \"\"\"\n",
    "    Calculates the sentiment score for a given HTML content and title using a specified model and tokenizer.\n",
    "\n",
    "    Args:\n",
    "        html_content (str): The HTML content to analyze.\n",
    "        title_sentences (str): The title sentences to analyze.\n",
    "        name (str): The name to search for in the content and title.\n",
    "        model: The transformer model for sentiment analysis.\n",
    "        tokenizer: The tokenizer associated with the model.\n",
    "\n",
    "    Returns:\n",
    "        float: The sentiment score of the article.\n",
    "    \"\"\"\n",
    "    # For html_content\n",
    "    html_content = clean_string(text = html_content)  #\n",
    "    title_sentences = clean_string(text = title_sentences) #\n",
    "    html_content = re.sub(re.escape(title_sentences), \"\", html_content) # this code eliminates the duplicated title text in html_content\n",
    "    \n",
    "    content_inputs = tokenizer.encode_plus(html_content, add_special_tokens=False, return_tensors='pt').to(device)\n",
    "    input_dict = _long_text(content_inputs, chunksize = 512)\n",
    "    with torch.no_grad(): \n",
    "        content_outputs = model(**input_dict)\n",
    "    content_sentences = tokenizer.batch_decode(input_dict['input_ids'],skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "    content_scores = torch.nn.functional.softmax(content_outputs.logits, dim=-1)\n",
    "    normalised_content_scores = torch.matmul(\n",
    "        content_scores, torch.tensor([-1.0, -0.5, 0, 0.5, 1.0])\n",
    "    ).tolist()\n",
    "    \n",
    "\n",
    "    # For title content\n",
    "    title_inputs = tokenizer(title_sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():       \n",
    "        title_outputs = model(**title_inputs)\n",
    "    title_scores = torch.nn.functional.softmax(title_outputs.logits, dim=-1)\n",
    "    normalised_title_scores = torch.matmul(\n",
    "        title_scores, torch.tensor([-1.0, -0.5, 0, 0.5, 1.0])\n",
    "    ).tolist()\n",
    "\n",
    "    mentions = 0\n",
    "    score = 0.0\n",
    "    count = 0\n",
    "    for sentence, sentiment in zip(\n",
    "        content_sentences, normalised_content_scores\n",
    "    ):\n",
    "        multiplier = 1\n",
    "        if name.lower() in sentence.lower():\n",
    "            mentions += sentence.lower().count(name.lower())\n",
    "            multiplier = 5\n",
    "\n",
    "        count += multiplier\n",
    "        score += sentiment * multiplier\n",
    "\n",
    "    for sentence, sentiment in zip(title_sentences, normalised_title_scores):\n",
    "        mentions += sentence.lower().count(name.lower())\n",
    "        multiplier = 5\n",
    "        count += multiplier\n",
    "        score += sentiment * multiplier\n",
    "\n",
    "    average_score = score / count\n",
    "    article_score = average_score * 50 + 50\n",
    "\n",
    "    return round(article_score, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text = \"What is Volkswagen accused of?\\nIt's been dubbed the \\\"diesel dupe\\\". In September, the Environmental Protection Agency (EPA) found that many VW cars being sold in America had a \\\"defeat device\\\" - or software - in diesel engines that could detect when they were being tested, changing the performance accordingly to improve results. The German car giant has since admitted cheating emissions tests in the US.\\nVW has had a major push to sell diesel cars in the US, backed by a huge marketing campaign trumpeting its cars' low emissions. The EPA's findings cover 482,000 cars in the US only, including the VW-manufactured Audi A3, and the VW models Jetta, Beetle, Golf and Passat. But VW has admitted that about 11 million cars worldwide, including eight million in Europe, are fitted with the so-called \\\"defeat device\\\".\\nThe company has also been accused by the EPA of modifying software on the 3 litre diesel engines fitted to some Porsche and Audi as well as VW models. VW has denied the claims, which affect at least 10,000 vehicles.\\nIn November, VW said it had found \\\"irregularities\\\" in tests to measure carbon dioxide emissions levels that could affect about 800,000 cars in Europe - including petrol vehicles. However, in December it said that following investigations, it had established that this only affected about 36,000 of the cars it produces each year.\\nThis 'defeat device' sounds like a sophisticated piece of kit.\\nFull details of how it worked are sketchy, although the EPA has said that the engines had computer software that could sense test scenarios by monitoring speed, engine operation, air pressure and even the position of the steering wheel.\\nWhen the cars were operating under controlled laboratory conditions - which typically involve putting them on a stationary test rig - the device appears to have put the vehicle into a sort of safety mode in which the engine ran below normal power and performance. Once on the road, the engines switched out of this test mode.\\nThe result? The engines emitted nitrogen oxide pollutants up to 40 times above what is allowed in the US.\\nWhat has been VW's response?\\n\\\"We've totally screwed up,\\\" said VW America boss Michael Horn, while the group's chief executive at the time, Martin Winterkorn, said his company had \\\"broken the trust of our customers and the public\\\". Mr Winterkorn resigned as a direct result of the scandal and was replaced by Matthias Mueller, the former boss of Porsche.\\n\\\"My most urgent task is to win back trust for the Volkswagen Group - by leaving no stone unturned,\\\" Mr Mueller said on taking up his new post.\\nVW has also launched an internal inquiry.\\nBut that's unlikely to be the end of the financial impact. The EPA has the power to fine a company up to $37,500 for each vehicle that breaches standards - a maximum fine of about $18bn.\\nThe costs of possible legal action by car owners and shareholders \\\"cannot be estimated at the current time\\\", VW added.\\nHow widespread are VW's problems?\\nWhat started in the US has spread to a growing number of countries. The UK, Italy, France, South Korea, Canada and, of course, Germany, have opened investigations. Throughout the world, politicians, regulators and environmental groups are questioning the legitimacy of VW's emissions testing.\\nVW will recall 8.5 million cars in Europe, including 2.4 million in Germany and 1.2 million in the UK, and 500,000 in the US as a result of the emissions scandal.\\nNo wonder the carmaker's shares have fallen by about a third since the scandal broke.\\nWill more heads roll?\\nIt's still unclear who knew what and when, although VW must have had a chain of management command that approved fitting cheating devices to its engines, so further departures are likely.\\nChristian Klingler, a management board member and head of sales and marketing is leaving the company, although VW said this was part of long-term planned structural changes and was not related to recent events.\\nIn 2014, in the US, regulators raised concerns about VW emissions levels, but these were dismissed by the company as \\\"technical issues\\\" and \\\"unexpected\\\" real-world conditions. If executives and managers wilfully misled officials (or their own VW superiors) it's difficult to see them surviving.\\nAre other carmakers implicated?\\nThat's for the various regulatory and government inquiries to determine. California's Air Resources Board is now looking into other manufacturers' testing results. Ford, BMW and Renault-Nissan have said they did not use \\\"defeat devices\\\", while other firms have either not commented or simply stated that they comply with the law.\\nThe UK trade body for the car industry, the SMMT, said: \\\"The EU operates a fundamentally different system to the US - with all European tests performed in strict conditions as required by EU law and witnessed by a government-appointed independent approval agency.\\\"\\nBut it added: \\\"The industry acknowledges that the current test method is outdated and is seeking agreement from the European Commission for a new emissions test that embraces new testing technologies and is more representative of on-road conditions.\\\"\\nThat sounds like EU testing rules need tightening, too.\\nEnvironmental campaigners have long argued that emissions rules are being flouted. \\\"Diesel cars in Europe operate with worse technology on average than the US,\\\" said Jos Dings, from the pressure group Transport & Environment. \\\"Our latest report demonstrated that almost 90% of diesel vehicles didn't meet emission limits when they drive on the road. We are talking millions of vehicles.\\\"\\nCar analysts at the financial research firm Bernstein agree that European standards are not as strict as those in the US. However, the analysts said in a report that there was, therefore, \\\"less need to cheat\\\". So, if other European carmakers' results are suspect, Bernstein says the \\\"consequences are likely to be a change in the test cycle rather than legal action and fines\\\".\\nIt's all another blow for the diesel market.\\nCertainly is. Over the past decade and more, carmakers have poured a fortune into the production of diesel vehicles - with the support of many governments - believing that they are better for the environment. Latest scientific evidence suggests that's not the case, and there are even moves to limit diesel cars in some cities.\\nDiesel sales were already slowing, so the VW scandal came at a bad time. \\\"The revelations are likely to lead to a sharp fall in demand for diesel engine cars,\\\" said Richard Gane, automotive expert at consultants Vendigital.\\n\\\"In the US, the diesel car market currently represents around 1% of all new car sales and this is unlikely to increase in the short to medium term.\\n\\\"However, in Europe the impact could be much more significant, leading to a large tranche of the market switching to petrol engine cars virtually overnight.\\\"\"\n",
    "summary = \"In September, the Environmental Protection Agency (EPA) found that many VW cars being sold in America had a \\\"defeat device\\\" - or software - in diesel engines that could detect when they were being tested, changing the performance accordingly to improve results. VW has had a major push to sell diesel cars in the US, backed by a huge marketing campaign trumpeting its cars' low emissions. The company has also been accused by the EPA of modifying software on the 3 litre diesel engines fitted to some Porsche and Audi as well as VW models. In November, VW said it had found \\\"irregularities\\\" in tests to measure carbon dioxide emissions levels that could affect about 800,000 cars in Europe - including petrol vehicles. VW will recall 8.5 million cars in Europe, including 2.4 million in Germany and 1.2 million in the UK, and 500,000 in the US as a result of the emissions scandal.\"\n",
    "title = \"Volkswagen: The scandal explained - BBC News\"\n",
    "name = \"Volkswagen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1453 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "article_score = _calculate_sentiment(html_content = html_text, title_sentences = title, name=name, model= model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.4511"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('bert_cloudrun')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1975ba15f5c6f49e9393a9ffcbc1714a9b9c74c65b1617749f5a6fb7923474c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
